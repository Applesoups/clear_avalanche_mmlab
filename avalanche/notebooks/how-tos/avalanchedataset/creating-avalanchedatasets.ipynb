{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "description: Creation and manipulation of AvalancheDatasets and its subclasses.\n",
    "---\n",
    "\n",
    "# Creating AvalancheDatasets\n",
    "\n",
    "The *AvalancheDataset* is an implementation of the PyTorch Dataset class which comes with many out-of-the-box functionalities. The *AvalancheDataset* (an its few subclass) are extensively used through the whole Avalanche library as the reference way to manipulate datasets:\n",
    "\n",
    "- The dataset carried by the `experience.dataset` field is always an *AvalancheDataset*.\n",
    "- Benchmark creation functions accept *AvalancheDataset*s to create benchmarks where a finer control over task labels is required.\n",
    "- Internally, benchmarks are created by manipulating *AvalancheDataset*s.\n",
    "\n",
    "This first *Mini How-To* will guide through the main ways you can use to **instantiate an _AvalancheDataset_** while the **other Mini How-Tos ([complete list here](https://avalanche.continualai.org/how-tos/avalanchedataset)) will show how to use its functionalities**.\n",
    "\n",
    "It is warmly recommended to **run this page as a notebook** using Colab (info at the bottom of this page).\n",
    "\n",
    "Let's start by installing avalanche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avalanche-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AvalancheDataset vs PyTorch Dataset\n",
    "This mini How-To will guide you through the main ways used to instantiate an *AvalancheDataset*.\n",
    "\n",
    "First thing: the base class `AvalancheDataset` is a **wrapper for existing datasets**. Only two things must be considered when wrapping an existing dataset:\n",
    "\n",
    "- Apart from the x and y values, the resulting AvalancheDataset will also return a third value: the task label (which defaults to 0).\n",
    "- The wrapped dataset must contain a valid **targets** field.\n",
    "\n",
    "The **targets field** is available is nearly all *torchvision* datasets. It must be a list containing the label for each data point (usually the y value). In this way, Avalanche can use that field when instantiating benchmarks like the \"Class/Task-Incremental* and *Domain-Incremental* ones.\n",
    "\n",
    "Avalanche exposes 4 classes of *AvalancheDataset*s which map exactly the 4 *Dataset* classes offered by PyTorch:\n",
    "- `AvalancheDataset`: the base class, which acts a wrapper to existing *Dataset* instances.\n",
    "- `AvalancheTensorDataset`: equivalent to PyTorch `TesnsorDataset`.\n",
    "- `AvalancheSubset`: equivalent to PyTorch `Subset`.\n",
    "- `AvalancheConcatDataset`: equivalent to PyTorch `ConcatDataset`.\n",
    "\n",
    "## üõ†Ô∏è Create an AvalancheDataset\n",
    "Given a dataset (like MNIST), an *AvalancheDataset* can be instantiated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Instantiate the MNIST train dataset from torchvision\n",
    "mnist_dataset = MNIST('mnist_data', download=True)\n",
    "\n",
    "# Create the AvalancheDataset\n",
    "mnist_avalanche_dataset = AvalancheDataset(mnist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Just like any other Dataset, a data point can be obtained using the `x, y = dataset[idx]` syntax. **When obtaining a data point from an AvalancheDataset, an additional third value (the task label) will be returned**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=<PIL.Image.Image image mode=L size=28x28 at 0x7F75CDC5B550>, y=5\n",
      "x=<PIL.Image.Image image mode=L size=28x28 at 0x7F75CDC5B5B0>, y=5, t=0\n"
     ]
    }
   ],
   "source": [
    "# Obtain the first instance from the original dataset\n",
    "x, y = mnist_dataset[0]\n",
    "print(f'x={x}, y={y}')\n",
    "# Output: \"x=<PIL.Image.Image image mode=L size=28x28 at 0x7FBEDFDB2430>, y=5\"\n",
    "\n",
    "# Obtain the first instance from the AvalancheDataset\n",
    "x, y, t = mnist_avalanche_dataset[0]\n",
    "print(f'x={x}, y={y}, t={t}')\n",
    "# Output: \"x=<PIL.Image.Image image mode=L size=28x28 at 0x7FBEEFD3A850>, y=5, t=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful tip:** if you are not sure if you are dealing with a PyTorch *Dataset* or an *AvalancheDataset*, or if you want to ignore task labels, you can use this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use \"x, y, *_\" to manage both kinds of Datasets\n",
    "x, y, *_ = mnist_dataset[0]  # OK\n",
    "x, y, *_ = mnist_avalanche_dataset[0]  # OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The AvalancheTensorDataset\n",
    "The PyTorch *TensorDataset* is one of the most useful Dataset classes as it can be used to quickly prototype the data loading part of your code.\n",
    "\n",
    "A *TensorDataset* can be wrapped in an AvalancheDataset just like any Dataset, but this is not much convenient, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([0.8383, 0.1409, 0.7622, 0.6625, 0.6322, 0.1188, 0.7383]), y=4, t=0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "# Create 10 instances described by 7 features \n",
    "x_data = torch.rand(10, 7)\n",
    "\n",
    "# Create the class labels for the 10 instances\n",
    "y_data = torch.randint(0, 5, (10,))\n",
    "\n",
    "# Create the tensor dataset\n",
    "tensor_dataset = TensorDataset(x_data, y_data)\n",
    "\n",
    "# Wrap it in an AvalancheDataset\n",
    "wrapped_tensor_dataset = AvalancheDataset(tensor_dataset)\n",
    "\n",
    "# Obtain the first instance from the dataset\n",
    "x, y, t = wrapped_tensor_dataset[0]\n",
    "print(f'x={x}, y={y}, t={t}')\n",
    "# Output: \"x=tensor([0.6329, 0.8495, 0.1853, 0.7254, 0.7893, 0.8079, 0.1106]), y=4, t=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instead, it is recommended to use the AvalancheTensorDataset** class to get the same result. In this way, you can just skip one intermediate step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([0.8383, 0.1409, 0.7622, 0.6625, 0.6322, 0.1188, 0.7383]), y=4, t=0\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheTensorDataset\n",
    "\n",
    "# Create the tensor dataset\n",
    "avl_tensor_dataset = AvalancheTensorDataset(x_data, y_data)\n",
    "\n",
    "# Obtain the first instance from the AvalancheTensorDataset\n",
    "x, y, t = avl_tensor_dataset[0]\n",
    "print(f'x={x}, y={y}, t={t}')\n",
    "# Output: \"x=tensor([0.6329, 0.8495, 0.1853, 0.7254, 0.7893, 0.8079, 0.1106]), y=4, t=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, **AvalancheDataset will automatically populate its _targets_ field by using the values from the second Tensor** (which usually contains the Y values). This behaviour can be customized by passing a custom `targets` constructor parameter (by either passing a list of targets or the index of the Tensor to use).\n",
    "\n",
    "The cell below shows the content of the target field of the dataset created in the cell above. Notice that the *targets* field has been filled with the content of the second Tensor (*y\\_data*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data= tensor([4, 0, 2, 2, 1, 1, 0, 0, 0, 1])\n",
      "targets field= [tensor(4), tensor(0), tensor(2), tensor(2), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1)]\n"
     ]
    }
   ],
   "source": [
    "# Check the targets field\n",
    "print('y_data=', y_data)\n",
    " # Output: \"y_data= tensor([4, 3, 3, 2, 0, 1, 3, 3, 3, 2])\"\n",
    "\n",
    "print('targets field=', avl_tensor_dataset.targets)\n",
    "# Output: \"targets field= [tensor(4), tensor(3), tensor(3), tensor(2), \n",
    "#          tensor(0), tensor(1), tensor(3), tensor(3), tensor(3), tensor(2)]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The AvalancheSubset and AvalancheConcatDataset classes\n",
    "Avalanche offers the `AvalancheSubset` and `AvalancheConcatDataset` implementations that extend the functionalities of PyTorch *Subset* and *ConcatDataset*.\n",
    "\n",
    "Regarding the subsetting operation, `AvalancheSubset` behaves in the same way the PyTorch `Subset` class does: both implementations accept a dataset and a list of indices as parameters. The resulting Subset is not a copy of the dataset, it's just a view. This is similar to creating a view of a NumPy array by passing a list of indexes using the `numpy_array[list_of_indices]` syntax. This can be used to both *create a smaller dataset* and to *change the order of data points* in the dataset.\n",
    "\n",
    "Here we create a toy dataset in which each X and Y values are *int*s. We then obtain a subset of it by creating an **AvalancheSubset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subset contains 4 instances.\n",
      "x=50, y=10, t=0\n",
      "x=55, y=15, t=0\n",
      "x=58, y=18, t=0\n",
      "x=52, y=12, t=0\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheSubset\n",
    "\n",
    "# Define the X values of 10 instances (each instance is an int)\n",
    "x_data_toy = [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
    "\n",
    "# Define the class labels for the 10 instances\n",
    "y_data_toy = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "# Create  the tensor dataset\n",
    "# Note: AvalancheSubset can also be applied to PyTorch TensorDataset directly!\n",
    "# However, note that PyTorch TensorDataset doesn't support Python lists...\n",
    "# ... (it only supports Tensors) while AvalancheTensorDataset does.\n",
    "toy_dataset = AvalancheTensorDataset(x_data_toy, y_data_toy) \n",
    "\n",
    "# Define the indices for the subset\n",
    "# Here we want to obtain a subset containing only the data points...\n",
    "# ... at indices 0, 5, 8, 2 (in this specific order)\n",
    "subset_indices = [0, 5, 8, 2]\n",
    "\n",
    "# Create the subset\n",
    "avl_subset = AvalancheSubset(toy_dataset, indices=subset_indices)\n",
    "print('The subset contains', len(avl_subset), 'instances.')\n",
    "# Output: \"The subset contains 4 instances.\"\n",
    "\n",
    "# Obtain instances from the AvalancheSubset\n",
    "for x, y, t in avl_subset:\n",
    "    print(f'x={x}, y={y}, t={t}')\n",
    "# Output:\n",
    "# x=50, y=10, t=0\n",
    "# x=55, y=15, t=0\n",
    "# x=58, y=18, t=0\n",
    "# x=52, y=12, t=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation is even simpler. Just like with PyTorch *ConcatDataset*, one can easily concatentate datasets with **AvalancheConcatDataset**.\n",
    "\n",
    "Both *AvalancheConcatDataset* and PyTorch *ConcatDataset* accept a list of datasets to concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concat dataset contains 10 instances.\n",
      "x=50, y=10, t=0\n",
      "x=51, y=11, t=0\n",
      "x=52, y=12, t=0\n",
      "x=53, y=13, t=0\n",
      "x=54, y=14, t=0\n",
      "x=60, y=20, t=0\n",
      "x=61, y=21, t=0\n",
      "x=62, y=22, t=0\n",
      "x=63, y=23, t=0\n",
      "x=64, y=24, t=0\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheConcatDataset\n",
    "\n",
    "# Define the 2 datasets to be concatenated\n",
    "x_data_toy_1 = [50, 51, 52, 53, 54]\n",
    "y_data_toy_1 = [10, 11, 12, 13, 14]\n",
    "x_data_toy_2 = [60, 61, 62, 63, 64]\n",
    "y_data_toy_2 = [20, 21, 22, 23, 24]\n",
    "\n",
    "# Create the datasets\n",
    "toy_dataset_1 = AvalancheTensorDataset(x_data_toy_1, y_data_toy_1) \n",
    "toy_dataset_2 = AvalancheTensorDataset(x_data_toy_2, y_data_toy_2) \n",
    "\n",
    "# Create the concat dataset\n",
    "avl_concat = AvalancheConcatDataset([toy_dataset_1, toy_dataset_2])\n",
    "print('The concat dataset contains', len(avl_concat), 'instances.')\n",
    "# Output: \"The concat dataset contains 10 instances.\"\n",
    "\n",
    "# Obtain instances from the AvalancheConcatDataset\n",
    "for x, y, t in avl_concat:\n",
    "    print(f'x={x}, y={y}, t={t}')\n",
    "# Output:\n",
    "# x=51, y=11, t=0\n",
    "# x=52, y=12, t=0\n",
    "# x=53, y=13, t=0\n",
    "# x=54, y=14, t=0\n",
    "# x=60, y=20, t=0\n",
    "# x=61, y=21, t=0\n",
    "# x=62, y=22, t=0\n",
    "# x=63, y=23, t=0\n",
    "# x=64, y=24, t=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation wrap-up\n",
    "This *Mini How-To* showed you how to **create instances of AvalancheDataset (and its subclasses)**.\n",
    "\n",
    "Other *Mini How-To*s will guide you through the functionalities offered by AvalancheDataset. The list of *Mini How-To*s can be found [here](https://avalanche.continualai.org/how-tos/avalanchedataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory by clicking here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/how-tos/avalanchedataset/creating-avalanchedatasets.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
